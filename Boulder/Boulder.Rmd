---
title: "rtweet tutorial"
subtitle: "<br/>with R-Ladies Boulder"
author: "🌈 Zane Dax (She/They) 🌈"
institute: "@StarTrek_Lt"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: [default, rladies, rladies-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
options(htmltools.dir.version = FALSE)
```




class: inverse,center
background-image: url("slides_files/RLadies\ bg.png")
# rtweet

![rladies](rtweet_R_logo 2.png)







---
class: inverse, center, middle

# Get Started

---





# rtweet library

Install the **rtweet** package from [Github](https://github.com/ropensci/rtweet) or from CRAN:

```{r eval=FALSE, tidy=FALSE, message=FALSE, warning=FALSE}
# install.packages("rtweet")
library(rtweet)
```

--

You are required to have a Twitter API access key in order to 
use the library.

- A user *must* authenticate their interaction with Twitter's API. If 
you already have an access token key, then a browser popup will 
appear where you need to click on permissions and verification.

--

- Once you have this set up you are ready to go

--

.footnote[
[1] my documentation is based on using a MacOS version 12.1

[2] See Twitter API documentation for full details and explanations
]



---
class: inverse, middle, center

# Data Mine the hashtags

---



# Needed libraries

You will require a few more libraries to follow along with the slides: 

```{r message=FALSE, warning=FALSE}
library(rtweet)     # needed for Twitter API
library(tidyverse)  # for data manipulation
library(ggplot2)    # for plotting 
library(tidytext)   # for text analysis
library(ggraph)     # graphing words
library(showtext)   # for font styling
library(widyr)      # dataframe manipulation

library(lexicon)    # for regular expressions
library(textclean)
```

If you are not interested in graphing the word associations and frequencies, then you just need:
- rtweet
- tidyverse
- ggplot


---

# Step 1 - Find a #hashtag

You can see a trending hashtag on Twitter or use a word / phrase to get tweets on that specific hashtag/ phrase. For this example we will use #DragRace. The rate limit is 
**max** 18,000 tweets per API call. We are not interested in retweets for this hashtag and set the function to false. Language settings are set to return English tweets only.
**Note**: You can search tweets <= 9 days ago for free, otherwise you need to pay Twitter to access older tweets.

**search Twitter for all tweets with #DragRace**

```
# give your search_tweets() a variable

DragRace_tweets = search_tweets2(
  "#DragRace",         # hashtag we are interested in
  n= 18000,            # max amount of tweets in 1 API request
  lang = "en",         # English
  include_rts = FALSE  # no retweets
)
```

It is **strongly advised** you make use of variable names for your Twitter data as to avoid `rate limit` (getting timed-out for 15 minutes or Twitter Developer account suspended which is the account that has the API key). If you rate_limit too often, there will be the message in the console and you will lose privileges with the Twitter Developer account which makes your API key void.
---



--- 
# Step 2 - Save your search Tweets

This is very important to do as to avoid executing the `search_tweets2()` function again within 15 minutes and seeing a `rate_limit` warning message in the console. Seeing a `rate_limit` warning is scary to see but really means you have to wait at least 15 minutes to try to run the code again. 

To get `rate limit` info for specific token (function call)
- `token <- get_tokens()`
- `rate_limit(token)`
- `rate_limit(token, "search_tweets")`

```
#   query         limit remaining reset    reset_at            timestamp           
# 1 search/tweets   180       180 15.0119… 2021-09-02 09:42:08 2021-09-02 09:27:08 
```

**SAVE YOUR TWITTER SEARCHES**
```
DragRace_tweets = write_as_csv(
  DragRace_tweets,               # variable name used
  file_name = "DragRace_tweets", # new variable name for CSV file
  prepend_ids = TRUE,            # set to true 
  na = "",
  fileEncoding = "UTF-8"         # save file in UTF-8 
)
```


---
# Step 3 - read in saved data

```{r include=FALSE}
DragRace_tweets = read_twitter_csv(file ="DragRace_tweets.csv" , unflatten = FALSE)
```

DragRace_tweets = read_twitter_csv(file = "DragRace_tweets.csv" , 
  unflatten = FALSE)

`DragRace_tweets` has 11807 rows (obs.) and 92 columns (variables)

---
class: inverse, middle, center

# Text Analysis of Tweets






---
# #DragRace

**The Twitter API returns lots of meta-data information.** 
Only 6 rows of the Tweets dataframe text is shown. This is raw Twitter text data that is messy with `url`s, emojis and `\n` new lines.

this is `head(DragRace_tweets$text)`
```{r echo=FALSE}
# head(DragRace_tweets$text)

```

[1] "Look who I bumped into before “Marry Me” Premiere. The longest reigning queen, Angele Anang @angeleanang 👸🏽from Drag Race Thailand! 💓\n.\nPhoto by: DJ Poupée @splendidchick \n.\n#DragRaceThailand \n#RuPaulsDragRace\n#DragRace https://t.co/kgQnnJHLQA"                       
[2] "Teaching the work husband to speak in #DragRace gifs is the greatest moment of the school year so far! https://t.co/fdYIPoBf1V"                                                                    
[3] "Whoever has the Gold Bar, LaskaTox will take it from her and give it to Roxxxy Andrews. #DragRace"               
[4] "@pride please read below and help our friends! @UKPrideNetwork #dragqueens #drag #dragrace our friends last wish ⬇️ https://t.co/TxAtTVqpCd"                                                                                  






---
# just the text - 1

To clean the Twitter data we need to remove url links and emojis.
```{r }
# ======== remove URLs,  emojis & non-ASCII char
# DragRace_tweets$stripped_text = replace_non_ascii2(DragRace_tweets$text)
# DragRace_tweets$stripped_text = replace_non_ascii2(DragRace_tweets$stripped_text)

DragRace_tweets$stripped_text = gsub("http.*","", DragRace_tweets$text)
DragRace_tweets$stripped_text = gsub("https*","", DragRace_tweets$stripped_text)
```

- Note: the dataframe has `stripped_text` column (variable) which will be used again later for bigrams. 

[1] "Look who I bumped into before Marry Me Premiere. The longest reigning queen, Angele Anang @angeleanang from Drag Race Thailand! .Photo by: DJ Poupe @splendidchick .#DragRaceThailand #RuPaulsDragRace#DragRace "

[2] "Teaching the work husband to speak in #DragRace gifs is the greatest moment of the school year so far! "                                                                      
[3] "Whoever has the Gold Bar, LaskaTox will take it from her and give it to Roxxxy Andrews. #DragRace"                                                                                          





---
# just the text - 2

This code **tokenizes** the words to allow for easy word counts and further text analysis. 

```{r}
# ===== tidytext::unnest_tokens()
clean_DragRace_tweets = DragRace_tweets %>% 
  select(stripped_text) %>% 
  unnest_tokens(word, stripped_text) # tokens

head(clean_DragRace_tweets)
```


`clean_DragRace_tweets` has 161,743 obs. and 1 variable





---
# Tweet Word Counts - 1

Top 10 words, counted and sorted 

```{r}
# == plot, word counts of clean text  (stopwords included)
clean_DragRace_tweets %>% 
  count(word, sort= T) %>% 
  top_n(10) %>% 
  mutate(word= reorder(word, n))

```


---




--- 
# Tweet Word Counts - 1.1 
`stopwords` included
```{r echo=FALSE, fig.width=7, fig.height=7, message=FALSE, warning=FALSE, fig.retina=3}
clean_DragRace_tweets %>% 
  count(word, sort= T) %>% 
  top_n(20) %>% 
  mutate(word= reorder(word, n)) %>% 
  ggplot( aes(x= word, y= n))+
  geom_col(fill= "#d534eb")+
  # ggdark::dark_mode()+
  theme_light() +
  coord_flip()+
  labs(title = "Twitter tweet word counts for #DragRace",
       x="unique words",
       y= "Count")+
  theme(text = element_text(family = 'Poppins', size = 12))

```


 
 
 
 
---
# Tweet Word Counts - 1.2

`stopwords` are removed from the data. `clean_DragRace_words` has 82441 obs.
```{r warning=FALSE, message=FALSE}
# ========== tidytext stop_words + anti_join
clean_DragRace_words = clean_DragRace_tweets %>% 
  anti_join(stop_words)

clean_DragRace_words %>% 
  count(word, sort= T) %>% 
  top_n(10) %>%
  filter(word > 10)
```


---
# Tweet Word Counts - 1.3
```{r echo=FALSE, fig.width=10, message=FALSE, warning=FALSE, fig.retina=3}
clean_DragRace_words %>% 
  count(word, sort= T) %>% 
  top_n(40) %>%
  filter(word > 10) %>% 
  # filter(!word == c('s4','2',"i' \tm",'phi','e1','s4','2','e1','el','s2',"i'm")) %>%
  mutate(word = as_factor(word),
    word= reorder(word, n)) %>% 
  ggplot( aes(x= word, y= n))+
  geom_text( aes(label= n, vjust= .5, hjust= -1), color= 'black')+
  geom_col(fill= "#d534eb")+
  # ggdark::dark_mode()+
  theme_light() +
  coord_flip()+
  labs(title = "Twitter tweet word counts for #DragRace",
       subtitle = "top 40 words. Retweets excluded. N = 82,441",
       x="unique words",
       y= "Count",
      )+ 
  theme(
   text =  element_text(family = 'Poppins'),
   plot.title = element_text(size = 15, 
                             face = 'bold',
                             color ="#e757fa" ),
    axis.title = element_text(size = 13),
    axis.text = element_text(size = 12),
   plot.caption = element_text(color = 'grey40', hjust = 0)
   )
```




---

# bigram and n-grams

```{r warning=FALSE, message=FALSE}
# ============= NETWORK OF WORDS !
library(widyr)

# bigrams. n-grams
DragRace_tweets_paired_words = DragRace_tweets %>% 
  select(stripped_text) %>% 
  unnest_tokens(paired_words, 
                stripped_text, 
                token= "ngrams",
                n = 2) # 2 for bigram pairing

DragRace_tweets_paired_words %>% 
  count(paired_words, sort = T) %>% 
  top_n(5)
```





---
# word pair splitting

we now split the bigrams into n-gram
```{r warning=FALSE, message=FALSE}
# ======== word pair splitting
library(tidyr)
DragRace_tweets_word_splits = DragRace_tweets_paired_words %>% 
  separate(paired_words, c('word1','word2'), sep = " ")

DragRace_tweets_filtered <- DragRace_tweets_word_splits %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)
# new bigram counts:
DragRace_tweets_words_counts <- DragRace_tweets_filtered %>%
  count(word1, word2, sort = TRUE)

head(DragRace_tweets_words_counts)
```


---
# Graph the words

Now that we have the n-grams and counted, we can graph them to see what words are associated together.

graph of word network
```
DragRace_tweets_words_counts %>% 
  filter(n >= 10) %>% 
  ggraph(layout = "fr")
```





---
```{r echo=FALSE, fig.width=12, fig.height=10, warning=FALSE, fig.retina=3}
DragRace_tweets_words_counts %>% 
  # words > 24
  filter(n >= 10) %>% 
  # graph_from_data_frame() %>% 
  ggraph(layout = "fr")+
  # ggdark::dark_mode()+
  theme_light()+
  geom_node_point(color="#e757fa", size=3)+
  geom_node_text( aes(label= name), vjust= 1.8, size= 4)+
  labs(title = "Twitter word network for #DragRace",
       subtitle = "Text Mining:  N= 21,998 tweets, word counts >= 10",
       x="",
       y="",
       )+
  theme(text = element_text(family = 'Poppins', color='black'),
        plot.title = element_text(color = '#e757fa', size = 14),
        plot.caption = element_text(color = 'grey60', hjust = 0, size = 10)
        )
```



<!-- ======  -->

---
class: inverse, middle, center

# #rstats Tweets 


---
# 1 & 2 - #rstats & save it

We can search Twitter for the #rstats hashtag. The `#` is optional. Spaces in the query is treated as AND, the OR *must* be capitalized.

```{r eval=FALSE, include=FALSE}
# rstats_searched_tweets = search_tweets(
#   q = "rstats OR RStats",
#   n = 6000,
#   type = "mixed",
#   include_rts = FALSE,
#   parse = TRUE,
#   verbose = TRUE,
#   retryonratelimit = FALSE,
#   lang="en"
# )
# 
# rstats_searched_tweets = write_as_csv(
#   rstats_searched_tweets,        # variable name used
#   file_name = "rstatsTweets",   # new variable name for CSV file
#   prepend_ids = TRUE,            # set to true
#   na = "",
#   fileEncoding = "UTF-8"         # save file in UTF-8
# )
```

```
rstats_searched_tweets = search_tweets(
  q = "rstats OR RStats",
  n = 6000,
  type = "mixed",
  include_rts = FALSE,
  parse = TRUE,
  verbose = TRUE,
  retryonratelimit = FALSE,
  lang="en"
)

rstats_searched_tweets = write_as_csv(
  rstats_searched_tweets,        # variable name used
  file_name = "rstatsTweets",    # new variable name for CSV file
  prepend_ids = TRUE,            # set to true
  na = "",
  fileEncoding = "UTF-8"         # save file in UTF-8
)
```






---
# 3 - read in the rstats tweets
```{r include=FALSE}
rstats_tweets = read_twitter_csv(file ="rstatsTweets.csv" , unflatten = FALSE)
```

```
rstats_tweets = read_twitter_csv(file ="rstatsTweets.csv" , 
  unflatten = FALSE)
```

# 4 - ts_plot
```
# using the time series plot function for Twitter data

ts_plot(rstats_tweets,          # dataframe of searched tweets
        by= "mins",             # can plot by seconds (default), mins, days, etc
        tz= "America/Edmonton", # your timezone 
        col= 'white'             # default is black
        )               
```





---
# 5 - time series plot

```{r echo=FALSE, fig.width=10, message=FALSE, warning=FALSE, fig.retina=3}
ts_plot(rstats_tweets, 
        by="mins",
        tz= "America/Edmonton",
        col='white'
        # trim = 1
        )+
  labs(title = "Twitter searched: 'rstats' OR 'RStats' tweets by minute ",
       x="date",
       y="count")+ 
  # ggdark::dark_mode()+
  # theme_light()+
  theme_minimal()+
  theme(
    text =  element_text(family = 'Poppins', size = 13, color = 'white'),
    plot.title = element_text(size = 15, 
                             face = 'bold',
                             color ="white" ),
    axis.title = element_text(size = 13),
    axis.text = element_text(size = 12),
    panel.background = element_rect(fill = '#442263')
   ) + theme(panel.grid.major = element_line(colour = "mediumorchid4"),
    panel.grid.minor = element_line(colour = "mediumorchid4"),
    axis.title = element_text(colour = "white"),
    axis.text = element_text(colour = "gray"),
    plot.background = element_rect(fill = "#442263"))
```





---
class: inverse, middle, center

# The End



---
# Further Information

- I have a detailed rtweet guide (learnr file) and [website](https://rtweetguide.netlify.app/) that tells you pretty much all of the documentation with understandable examples. 

- Twitter CSV datasets are available on GitHub for you to practice with for those without a API key. 

- **Thank you** RLadies Boulder for this opportunity 🍁



