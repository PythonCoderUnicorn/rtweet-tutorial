---
title: "rtweet tutorial"
subtitle: "<br/>with RLadies"
author: "ðŸŒˆ Zane Dax (She/They) ðŸŒˆ"
institute: ""
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: [default, rladies, rladies-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
options(htmltools.dir.version = FALSE)
```




class: inverse,center
background-image: url("slides_files/RLadies\ bg.png")
# rtweet

![rladies](slides_files/rtweet_R_logo 2.png)







---
class: inverse, center, middle

# Get Started

---





# rtweet library

Install the **rtweet** package from [Github](https://github.com/ropensci/rtweet):

```{r eval=FALSE, tidy=FALSE}
install.packages("rtweet")

library(rtweet)
```

--

You are required to have a Twitter API access key in order to 
use the library.

- A user *must* authenticate their interaction with Twitter's API. If 
you already have an access token key, then a browser popup will 
appear where you need to click on permissions and verification.

--

- Once you have this set up you are ready to go

--

.footnote[
[1] my documentation is based on using a MacOS version 12.1

[2] See Twitter API documentation for full details and explanations
]



---
class: inverse, middle, center

# Data Mine the hashtags

---



# Hello Twitter Data

You will require a few more libraries to follow along with the slides:

```{r message=FALSE, warning=FALSE}
library(rtweet)
library(tidyverse)
library(ggplot2)
library(tidytext)
library(igraph)
library(ggraph)
library(showtext)
library(widyr)
library(tidyr)
```

- `ggplot` is for data visualization 
- `tidytext` is for text analysis
- `ggraph` is for graphing the word frequencies together
- `showtext` is to change the font style (not required but suggested)


---




# Find a #hashtag

You can see a trending hashtag on Twitter or use a word to get tweets on that specific hashtag. For this example we will use #DragRace. The rate limit is 
18,000 tweets per API call. We are not interested in retweets for this hashtag and 
set the function to false. Language settings are set to return English tweets only.

```{r message=FALSE, warning=FALSE}
# search Twitter for all tweets with #DragRace 

DragRace_tweets = search_tweets2(
  "#DragRace",
  n= 18000,
  lang="en",
  include_rts=F
)
```


It is **strongly advised** you make use of variable names for your Twitter data as to avoid `rate limit` (getting timed-out or Twitter account suspended)







---

# #DragRace

The Twitter API returns lots of information.
```{r}
head(DragRace_tweets)
```

There are 92 columns for the Twitter data


---



# just the text - 1

The Twitter data we have is messy and has url links, need to remove them.
```{r}
# ======== remove URLs
DragRace_tweets$stripped_text = gsub("http.*","", DragRace_tweets$text)
DragRace_tweets$stripped_text = gsub("https*","", DragRace_tweets$stripped_text)

head(DragRace_tweets$stripped_text)

```

---
# just the text - 2

This code **tokenizes** the words to allow for easy word counts and further text analysis. 

```{r}
# ===== tidytext::unnest_tokens()
clean_DragRace_tweets = DragRace_tweets %>% 
  select(stripped_text) %>% 
  unnest_tokens(word, stripped_text) # tokens

head(clean_DragRace_tweets, 10)
```




---
# Tweet Word Counts - 1

Top 10 words, counted and sorted 

```{r}
# == plot, word counts of clean text  (stopwords included)
clean_DragRace_tweets %>% 
  count(word, sort= T) %>% 
  top_n(10) %>% 
  mutate(word= reorder(word, n))
```
---




--- 
# Tweet Word Counts - 1.1

```{r echo=FALSE, fig.width=10, message=FALSE, warning=FALSE}
clean_DragRace_tweets %>% 
  count(word, sort= T) %>% 
  top_n(20) %>% 
  mutate(word= reorder(word, n)) %>% 
  ggplot( aes(x= word, y= n))+
  geom_col(fill= "#d534eb")+
  ggdark::dark_mode()+
  coord_flip()+
  labs(title = "Twitter tweet word counts for #DragRace",
       x="unique words",
       y= "Count")+
  theme(text = element_text(family = 'Poppins', size = 12))
```


---
# Tweet Word Counts - 1.2

```{r warning=FALSE, message=FALSE}
# ========== tidytext stop_words + anti_join
clean_DragRace_words = clean_DragRace_tweets %>% 
  anti_join(stop_words)

clean_DragRace_words %>% 
  count(word, sort= T) %>% 
  top_n(10) %>%
  filter(word > 10)
```


---
# Tweet Word Counts - 1.3
```{r echo=FALSE, fig.width=10, message=FALSE, warning=FALSE}
clean_DragRace_words %>% 
  count(word, sort= T) %>% 
  top_n(40) %>%
  filter(word > 10) %>% 
  # filter(!word == c('s4','2',"i' \tm",'phi','e1','s4','2','e1','el','s2',"i'm")) %>%
  mutate(word = as_factor(word),
    word= reorder(word, n)) %>% 
  ggplot( aes(x= word, y= n))+
  geom_col(fill= "#d534eb")+
  ggdark::dark_mode()+
  coord_flip()+
  labs(title = "Twitter tweet word counts for #DragRace",
       subtitle = "top 40 words. Retweets excluded. N = 824",
       x="unique words",
       y= "Count",
       caption = "@StarTrek_Lt | Jan 3, 2022 | Source: Twitter API & {rtweet} package")+ 
  theme(
   text =  element_text(family = 'Poppins'),
   plot.title = element_text(size = 15, 
                             face = 'bold',
                             color ="#e757fa" ),
    axis.title = element_text(size = 13),
    axis.text = element_text(size = 12),
   plot.caption = element_text(color = 'grey40', hjust = 0)
   )
```




---

# bigram and n-grams

```{r warning=FALSE, message=FALSE}
# ============= NETWORK OF WORDS !
library(widyr)

# bigrams. n-grams
DragRace_tweets_paired_words = DragRace_tweets %>% 
  select(stripped_text) %>% 
  unnest_tokens(paired_words, 
                stripped_text, 
                token="ngrams",
                n= 2)

DragRace_tweets_paired_words %>% 
  count(paired_words, sort = T) %>% 
  top_n(5)
```





---

# word pair splitting

we now split the bigrams into n-gram
```{r warning=FALSE, message=FALSE}
# ======== word pair splitting
library(tidyr)

DragRace_tweets_word_splits = DragRace_tweets_paired_words %>% 
  separate(paired_words, c('word1','word2'), sep = " ")

DragRace_tweets_filtered <- DragRace_tweets_word_splits %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

# new bigram counts:
DragRace_tweets_words_counts <- DragRace_tweets_filtered %>%
  count(word1, word2, sort = TRUE)

head(DragRace_tweets_words_counts)
```


---

# Graph the words

Now that we have the n-grams and counted, we can graph them to see what words are associated together.


graph of word network
```
DragRace_tweets_words_counts %>% 
  filter(n >= 10) %>% 
  ggraph(layout = "fr")
```

---
```{r echo=FALSE, fig.width=12, fig.height=10}
DragRace_tweets_words_counts %>% 
  # words > 24
  filter(n >= 10) %>% 
  # graph_from_data_frame() %>% 
  ggraph(layout = "fr")+
  ggdark::dark_mode()+
  geom_node_point(color="#e757fa", size=3)+
  geom_node_text( aes(label= name), vjust= 1.8, size= 4)+
  labs(title = "Twitter word network for #DragRace",
       subtitle = "Text Mining:  N= 824 tweets, word counts >= 10",
       x="",
       y="",
       caption="@StarTrek_Lt | Jan 3, 2022 | Source: Twitter API | Sample Size: N= 3285 split words")+
  theme(text = element_text(family = 'Poppins'),
        plot.title = element_text(color = '#e757fa', size = 14),
        plot.caption = element_text(color = 'grey60', hjust = 0, size = 10)
        )
```

